{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b24a43a",
      "metadata": {
        "id": "3b24a43a"
      },
      "source": [
        "Open this notebook in Google Colab by clicking the link below:\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/relmonta/lorenz96/blob/main/lorenz96_surrogate_student.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b08c9fb5",
      "metadata": {
        "id": "b08c9fb5"
      },
      "source": [
        "# Practical: Using neural networks to learn surrogate models for chaotic systems\n",
        "Author: Rachid El Montassir\n",
        "\n",
        "\n",
        "- This notebook is inspired by the lecture notes of the course [\"Introduction to the principles and methods of data assimilation in the geosciences\"](https://cerea.enpc.fr/HomePages/bocquet/teaching/assim-mb-en-0.52.pdf) by M. Bocquet and A. Farchi.\n",
        "\n",
        "The aim of this lab is to introduce and compare different neural network architectures for modelling the dynamics of a chaotic system — the **Lorenz-96 model** — with a focus on **embedding physical structure into neural networks**. Through this exercise, you will learn how simple architectural choices (e.g. convolutions or integration schemes) can dramatically affect the predictive skill of a learned model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9184ef2",
      "metadata": {
        "id": "c9184ef2"
      },
      "source": [
        "## The Lorenz-96 System\n",
        "\n",
        "We consider the classical Lorenz-96 system of dimension $N_x$, governed by:\n",
        "\n",
        "$$\n",
        "\\frac{dx_i}{dt} = (x_{i+1} - x_{i-2})x_{i-1} - x_i + F\n",
        "$$\n",
        "\n",
        "where $F$ is a forcing parameter (typically $F = 8$), and indices are interpreted modulo $N_x$ (periodic boundary conditions). The system exhibits chaotic behaviour and serves as a toy model for high-dimensional, non-linear geophysical dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5774ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f5774ee",
        "outputId": "d0cea5c6-bd42-4c3b-ad89-dc5bd171f884",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/relmonta/lorenz96.git\n",
        "! pip install cmocean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0afd74",
      "metadata": {
        "id": "1e0afd74",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import cmocean\n",
        "import os\n",
        "from lorenz96.lorenz96_utils import Lorenz96, plot_lorenz96_trajectory, preprocess_dataset\n",
        "from lorenz96.lorenz96_utils import PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a613ee",
      "metadata": {
        "id": "e3a613ee"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d3be3c",
      "metadata": {
        "id": "b6d3be3c"
      },
      "source": [
        "### 1. Simple feedforward neural network\n",
        "A simple feedforward neural network that takes the state $x_t$ as input and outputs the state $x_{t+1}$ at the next time step. The model is trained to minimize the mean squared error between the predicted and true states.\n",
        "\n",
        "**Task**: Complete the code for the feedforward neural network model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9bbf137",
      "metadata": {
        "id": "c9bbf137",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class NaiveNetwork(nn.Module):\n",
        "    def __init__(self, Nx, num_layers=4):\n",
        "        super(NaiveNetwork, self).__init__()\n",
        "        self.Nx = Nx\n",
        "\n",
        "        layers = []\n",
        "        # TODO: add layers (num_layers - 1 in total) with Linear and ReLU\n",
        "        # layers.append(...)\n",
        "\n",
        "        self.hidden = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(128, Nx)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self, x, steps=1):\n",
        "        for _ in range(steps):\n",
        "            x = self.forward(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d913528d",
      "metadata": {
        "id": "d913528d"
      },
      "source": [
        "### Training\n",
        "The model is trained using the Adam optimizer with a starting learning rate of $10^{-3}$ and a batch size of 64. The training is performed for 100 epochs, and the model is evaluated on a validation set after each epoch. The best model is saved based on the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57b03cf",
      "metadata": {
        "id": "e57b03cf",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader, mean, std, device='cuda',\n",
        "                 model_type='hybrid', patience=15):\n",
        "        self.model_type = model_type\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.device = device\n",
        "        self.patience = patience\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, epochs=20, lr=1e-3):\n",
        "        print(f\"Training on device: {self.device}\")\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "        criterion = nn.MSELoss()\n",
        "        sstep = epochs // 6\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "            optimizer, step_size=sstep, gamma=0.5)  # Reduce LR every 10 epochs\n",
        "        losses = {'train': [], 'val': []}\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            for x, y in self.train_loader:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                pred = self.model(x)\n",
        "                loss = criterion(pred - x, y - x)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "            scheduler.step()\n",
        "            losses['train'].append(train_loss / len(self.train_loader))\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for x, y in self.val_loader:\n",
        "                    x, y = x.to(self.device), y.to(self.device)\n",
        "                    pred = self.model(x)\n",
        "                    loss = criterion(pred - x, y - x)\n",
        "                    val_loss += loss.item()\n",
        "            val_loss /= len(self.val_loader)\n",
        "            losses['val'].append(val_loss)\n",
        "\n",
        "            print(f\"[Epoch {epoch+1}] Train loss: {train_loss/len(self.train_loader):.4e} | \"\n",
        "                  f\"Val loss: {val_loss:.4e}\")\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                torch.save(self.model.state_dict(), PATH +\n",
        "                           f'{self.model_type}_best_network.pth')\n",
        "                # print(\n",
        "                #     f\"Best model saved as {PATH}{self.model_type}_best_network.pth\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= self.patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        self._plot_losses(losses)\n",
        "        print(f\"Final model saved as {PATH}{self.model_type}_network.pth\")\n",
        "        torch.save(self.model.state_dict(), PATH +\n",
        "                   f'{self.model_type}_network.pth')\n",
        "\n",
        "    def _plot_losses(self, losses):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(losses['train'], label='Train loss')\n",
        "        plt.plot(losses['val'], label='Validation loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f'{PATH}/{self.model_type}_training_loss.png', dpi=300)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fbda280",
      "metadata": {
        "id": "4fbda280"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd6a5c2",
      "metadata": {
        "id": "bbd6a5c2",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class Inference:\n",
        "    def __init__(self, model, mean, std, device='cuda', model_type='hybrid'):\n",
        "        self.model_type = model_type\n",
        "        self.model = model\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.device = device\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_trajectory(self, data_set, steps=40, Nx=40):\n",
        "        x_val = data_set[0][0]  # Get the first sample\n",
        "        x_val = x_val.unsqueeze(0).to(self.device)  # Add batch dimension\n",
        "        predicted_trajectory = np.zeros((steps, Nx))\n",
        "\n",
        "        for t in range(steps):\n",
        "            x_val = self.model.predict(x_val, steps=1)\n",
        "            x_val_out = x_val.cpu().numpy() * self.std + self.mean  # Denormalise\n",
        "            predicted_trajectory[t] = x_val_out\n",
        "\n",
        "        self._plot_trajectory(predicted_trajectory,\n",
        "                              title=f'{self.model_type.capitalize()} model predicted', vmin=-10, vmax=15)\n",
        "        # plot validation trajectory\n",
        "        val_trajectory = np.zeros((steps, Nx))\n",
        "        for t in range(steps):\n",
        "            x_val = data_set[t+1][0]\n",
        "            val_trajectory[t] = x_val.numpy() * self.std + self.mean\n",
        "        self._plot_trajectory(val_trajectory, title='True', vmin=-10, vmax=15)\n",
        "        # plot the error\n",
        "        error = predicted_trajectory - val_trajectory\n",
        "        self._plot_trajectory(error, title=f'{self.model_type.capitalize()} model error',\n",
        "                              vmin=-15, vmax=15)\n",
        "\n",
        "    def _plot_trajectory(self, trajectory, title='Predicted', vmin=None, vmax=None):\n",
        "        if vmin is not None and vmin == -vmax:\n",
        "            cmap = cmocean.cm.balance\n",
        "        else:\n",
        "            cmap = cmocean.cm.curl\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(trajectory.T, aspect='auto', cmap=cmap,\n",
        "                   origin='lower', interpolation='spline36', vmin=vmin, vmax=vmax)\n",
        "        cbar_label = 'Error value' if 'Error' in title else 'State value'\n",
        "        plt.colorbar(label=cbar_label)\n",
        "        plt.xlabel('Time step')\n",
        "        plt.ylabel('Lorenz96 variables')\n",
        "        plt.title(f'{title} Lorenz-96 trajectory')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\n",
        "            f'{PATH}/{title.replace(\" \", \"_\").lower()}_traj.png', dpi=300)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff06b18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "2ff06b18",
        "outputId": "ea061b4b-4bcf-44f3-b82a-5fe19bb4a331",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "Nt_train = 10000\n",
        "\n",
        "# Use double precision, simple precision could also be used\n",
        "torch.set_default_dtype(torch.float64)\n",
        "true_model = Lorenz96(Nx=40, dt=0.01, F=8.0, integrator='rk4')\n",
        "xt = true_model.generate_dataset(\n",
        "    Nt_train=Nt_train, Nt_spinup=1000, seed=42, Nt_shift=10)\n",
        "# change xt to double precision\n",
        "xt = xt.astype(np.float64)\n",
        "\n",
        "# Plot heatmap of trajectory\n",
        "plot_lorenz96_trajectory(xt, Nt=50, mode='heatmap')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904db4f2",
      "metadata": {
        "id": "904db4f2",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "train_set, val_set, mean, std = preprocess_dataset(xt)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae46db51",
      "metadata": {
        "id": "ae46db51",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_type=\"naive\"\n",
        "# Initialize model\n",
        "model = NaiveNetwork(Nx=true_model.Nx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350d9737",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "350d9737",
        "outputId": "c1485632-5913-4dfa-871d-11a060119323",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "# Train the model\n",
        "trainer = Trainer(model, train_loader, val_loader, mean, std,\n",
        "                    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                    model_type=model_type)\n",
        "trainer.train(epochs=epochs, lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b658e6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5b658e6e",
        "outputId": "b8846f05-4f52-41cc-e331-d786a58eae5f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "Nt = 25\n",
        "\n",
        "# Load the model, uncomment to load stored weights\n",
        "# model.load_state_dict(torch.load(\n",
        "#    f'{PATH}/stored/{model_type}_best_network.pth', weights_only=True))\n",
        "\n",
        "# Predictions\n",
        "inference = Inference(model, mean, std, model_type=model_type,\n",
        "                        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "inference.predict_trajectory(val_set, steps=Nt, Nx=true_model.Nx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563795bf",
      "metadata": {
        "id": "563795bf"
      },
      "source": [
        "### 2. Convolutional neural network (CNN)\n",
        "A convolutional neural network that takes the state $x_t$ as input and outputs the state $x_{t+1}$ at the next time step.\n",
        "\n",
        "**Task**: Complete the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dffffa60",
      "metadata": {
        "id": "dffffa60",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class ConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, Nx, num_filters=64, kernel_size=5):\n",
        "        super(ConvolutionalNetwork, self).__init__()\n",
        "        self.Nx = Nx\n",
        "\n",
        "        # TODO: define a first 1D convolutional layer (padding = kernel_size//2)\n",
        "        # TODO: define a second 1D convolutional layer to reduce back to 1 channel\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add channel dimension\n",
        "        x = x.unsqueeze(1)  # (B, 1, Nx)\n",
        "\n",
        "        # TODO: apply first convolution + ReLU\n",
        "        # TODO: apply second convolution\n",
        "\n",
        "        return x.squeeze(1)  # (B, Nx)\n",
        "\n",
        "    def predict(self, x, steps=1):\n",
        "        for _ in range(steps):\n",
        "            x = self.forward(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a874a28",
      "metadata": {
        "id": "7a874a28",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_type = 'conv'\n",
        "model = ConvolutionalNetwork(\n",
        "    Nx=true_model.Nx, num_filters=64, kernel_size=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1377b4e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1377b4e9",
        "outputId": "51979350-714c-4742-e952-d871067cbc72",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "# Train the model\n",
        "trainer = Trainer(model, train_loader, val_loader, mean, std,\n",
        "                    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                    model_type=model_type)\n",
        "trainer.train(epochs=epochs, lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16f0b75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a16f0b75",
        "outputId": "2b2fbc34-c1c1-4012-ed9c-3cf80142555f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "Nt = 25\n",
        "\n",
        "# Load the model, uncomment to load stored weights\n",
        "# model.load_state_dict(torch.load(\n",
        "#    f'{PATH}/stored/{model_type}_best_network.pth', weights_only=True))\n",
        "\n",
        "# Predictions\n",
        "inference = Inference(model, mean, std, model_type=model_type,\n",
        "                        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "inference.predict_trajectory(val_set, steps=Nt, Nx=true_model.Nx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "647368ca",
      "metadata": {
        "id": "647368ca"
      },
      "source": [
        "### 3. Hybrid model\n",
        "A hybrid model that combines: a CNN-based architecture for computing the tendency $\\frac{dx}{dt}$, an explicit integration scheme (Euler, RK2, RK4), and periodic padding to enforce spatial boundary conditions.\n",
        "\n",
        "\n",
        "- The **tendency** term approximate a learnable physical tendency function, inspired by differential equations with nonlinear terms. This means that we don't need to hard-code the theoretical tendency. Instead, we can learn it from the data. \n",
        "\n",
        "**Task**: Complete the code. Only the time integration schemes are to be implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2550c604",
      "metadata": {
        "id": "2550c604",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class HybridNetwork(nn.Module):\n",
        "    def __init__(self, Nx, num_filters=6, kernel_size=5, dt=0.01, integrator='euler'):\n",
        "        super(HybridNetwork, self).__init__()\n",
        "        self.Nx = Nx\n",
        "        self.dt = dt\n",
        "        self.border = kernel_size // 2\n",
        "        self.integrator = integrator\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=num_filters, kernel_size=kernel_size)\n",
        "        self.conv2 = nn.Conv1d(in_channels=num_filters * 2, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def pad(self, x):\n",
        "        # Periodic padding\n",
        "        left = x[..., -self.border:]\n",
        "        right = x[..., :self.border]\n",
        "        return torch.cat([left, x, right], dim=-1)\n",
        "\n",
        "    def tendency(self, x):\n",
        "        x = x.unsqueeze(1)  # (B, 1, Nx)\n",
        "        x_pad = self.pad(x)\n",
        "\n",
        "        x1 = self.conv1(x_pad)  # (B, F, Nx)\n",
        "        x2 = x1 ** 2            # Quadratic nonlinearity\n",
        "\n",
        "        x_cat = torch.cat([x1, x2], dim=1)  # (B, 2F, Nx)\n",
        "        out = self.conv2(x_cat)             # (B, 1, Nx)\n",
        "\n",
        "        return out.squeeze(1)               # (B, Nx)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.integrator == 'euler':\n",
        "            return self.euler_step(x)\n",
        "        elif self.integrator == 'rk2':\n",
        "            return self.rk2_step(x)\n",
        "        elif self.integrator == 'rk4':\n",
        "            return self.rk4_step(x)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid integrator. Use 'euler', 'rk2', or 'rk4'.\")\n",
        "\n",
        "    def euler_step(self, x):\n",
        "        # TODO: implement Euler time integration\n",
        "        pass\n",
        "\n",
        "    def rk2_step(self, x):\n",
        "        # TODO: implement RK2 time integration\n",
        "        pass\n",
        "\n",
        "    def rk4_step(self, x):\n",
        "        # TODO: implement RK4 time integration\n",
        "        pass\n",
        "\n",
        "    def predict(self, x, steps=1):\n",
        "        for _ in range(steps):\n",
        "            x = self.forward(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3f3e49",
      "metadata": {
        "id": "7e3f3e49",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "model_type=\"hybrid\"\n",
        "# hybrid network\n",
        "# Use the same parameters as the true model\n",
        "# Nx = true_model.Nx, dt = true_model.dt, integrator = true_model.integrator\n",
        "model = HybridNetwork(Nx=true_model.Nx, num_filters=6,\n",
        "                        kernel_size=5, dt=true_model.dt, integrator='rk4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f75e3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d2f75e3b",
        "outputId": "f73a9d38-b122-4ab9-d279-f618d2e9dde1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "# Train the model\n",
        "trainer = Trainer(model, train_loader, val_loader, mean, std,\n",
        "                    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                    model_type=model_type)\n",
        "trainer.train(epochs=epochs, lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdda9d73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bdda9d73",
        "outputId": "721bcedf-34ed-4c58-ee4a-116d0aa54008",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "Nt = 25\n",
        "\n",
        "# Load the model, uncomment to load stored weights\n",
        "# model.load_state_dict(torch.load(\n",
        "#    f'{PATH}/stored/{model_type}_best_network.pth', weights_only=True))\n",
        "\n",
        "# Predictions\n",
        "inference = Inference(model, mean, std, model_type=model_type,\n",
        "                        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "inference.predict_trajectory(val_set, steps=Nt, Nx=true_model.Nx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea5cc78",
      "metadata": {
        "id": "bea5cc78"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "In this practical session, we explored several neural network architectures for modelling the dynamics of chaotic systems.\n",
        "The key takeaway is that incorporating domain knowledge—such as the structure of the underlying physical equations or the use of numerical integration schemes—can significantly enhance the performance and robustness of learned surrogate models.\n",
        "\n",
        "These type of approaches are particularly relevant in the context of data assimilation, where surrogate models that respect physical laws are essential for reliable forecasting. This line of research is actively being pursued in operational weather and climate modelling, and it is expected to play an increasingly important role in the future of Earth system prediction."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
