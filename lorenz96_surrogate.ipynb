{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b24a43a",
   "metadata": {},
   "source": [
    "Open this notebook in Google Colab by clicking the link below:\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/relmonta/lorenz96/blob/main/lorenz96_surrogate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c9fb5",
   "metadata": {},
   "source": [
    "# Practical: Using neural networks to learn surrogate models for chaotic systems\n",
    "Author: Rachid El Montassir\n",
    "\n",
    "\n",
    "- This notebook is inspired by the lecture notes of the course [\"Introduction to the principles and methods of data assimilation in the geosciences\"](https://cerea.enpc.fr/HomePages/bocquet/teaching/assim-mb-en-0.52.pdf) by M. Bocquet and A. Farchi.\n",
    "\n",
    "The aim of this lab is to introduce and compare different neural network architectures for modelling the dynamics of a chaotic system — the **Lorenz-96 model** — with a focus on **embedding physical structure into neural networks**. Through this exercise, you will learn how simple architectural choices (e.g. convolutions or integration schemes) can dramatically affect the predictive skill of a learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9184ef2",
   "metadata": {},
   "source": [
    "## The Lorenz-96 System\n",
    "\n",
    "We consider the classical Lorenz-96 system of dimension $N_x$, governed by:\n",
    "\n",
    "$$\n",
    "\\frac{dx_i}{dt} = (x_{i+1} - x_{i-2})x_{i-1} - x_i + F\n",
    "$$\n",
    "\n",
    "where $F$ is a forcing parameter (typically $F = 8$), and indices are interpreted modulo $N_x$ (periodic boundary conditions). The system exhibits chaotic behaviour and serves as a toy model for high-dimensional, non-linear geophysical dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5774ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/relmonta/lorenz96.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0afd74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import cmocean\n",
    "import os\n",
    "from lorenz96_utils import Lorenz96, plot_lorenz96_trajectory, preprocess_dataset\n",
    "from lorenz96_utils import PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a613ee",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3be3c",
   "metadata": {},
   "source": [
    "### 1. Simple feedforward neural network\n",
    "A simple feedforward neural network that takes the state $x_t$ as input and outputs the state $x_{t+1}$ at the next time step. The model is trained to minimize the mean squared error between the predicted and true states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbf137",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveNetwork(nn.Module):\n",
    "    def __init__(self, Nx, num_layers=4):\n",
    "        super(NaiveNetwork, self).__init__()\n",
    "        self.Nx = Nx\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(Nx, 128),\n",
    "            nn.ReLU(),\n",
    "            *[\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(128, 128),\n",
    "                    nn.ReLU()\n",
    "                ) for _ in range(num_layers - 2)\n",
    "            ])\n",
    "        self.linear = nn.Linear(128, Nx)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x, steps=1):\n",
    "        for _ in range(steps):\n",
    "            x = self.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913528d",
   "metadata": {},
   "source": [
    "### Training\n",
    "The model is trained using the Adam optimizer with a starting learning rate of $10^{-3}$ and a batch size of 64. The training is performed for 100 epochs, and the model is evaluated on a validation set after each epoch. The best model is saved based on the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b03cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, mean, std, device='cuda',\n",
    "                 model_type='hybrid', patience=15):\n",
    "        self.model_type = model_type\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.device = device\n",
    "        self.patience = patience\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self, epochs=20, lr=1e-3):\n",
    "        print(f\"Training on device: {self.device}\")\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        sstep = epochs // 6\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=sstep, gamma=0.5)  # Reduce LR every 10 epochs\n",
    "        losses = {'train': [], 'val': []}\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            for x, y in self.train_loader:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                pred = self.model(x)\n",
    "                loss = criterion(pred - x, y - x)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            scheduler.step()\n",
    "            losses['train'].append(train_loss / len(self.train_loader))\n",
    "\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for x, y in self.val_loader:\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "                    pred = self.model(x)\n",
    "                    loss = criterion(pred - x, y - x)\n",
    "                    val_loss += loss.item()\n",
    "            val_loss /= len(self.val_loader)\n",
    "            losses['val'].append(val_loss)\n",
    "\n",
    "            print(f\"[Epoch {epoch+1}] Train loss: {train_loss/len(self.train_loader):.4e} | \"\n",
    "                  f\"Val loss: {val_loss:.4e}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.model.state_dict(), PATH +\n",
    "                           f'{self.model_type}_best_network.pth')\n",
    "                # print(\n",
    "                #     f\"Best model saved as {PATH}{self.model_type}_best_network.pth\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        self._plot_losses(losses)\n",
    "        print(f\"Final model saved as {PATH}{self.model_type}_network.pth\")\n",
    "        torch.save(self.model.state_dict(), PATH +\n",
    "                   f'{self.model_type}_network.pth')\n",
    "\n",
    "    def _plot_losses(self, losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(losses['train'], label='Train loss')\n",
    "        plt.plot(losses['val'], label='Validation loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'{PATH}/{self.model_type}_training_loss.png', dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbda280",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6a5c2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    def __init__(self, model, mean, std, device='cuda', model_type='hybrid'):\n",
    "        self.model_type = model_type\n",
    "        self.model = model\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_trajectory(self, data_set, steps=40, Nx=40):\n",
    "        x_val = data_set[0][0]  # Get the first sample\n",
    "        x_val = x_val.unsqueeze(0).to(self.device)  # Add batch dimension\n",
    "        predicted_trajectory = np.zeros((steps, Nx))\n",
    "\n",
    "        for t in range(steps):\n",
    "            x_val = self.model.predict(x_val, steps=1)\n",
    "            x_val_out = x_val.cpu().numpy() * self.std + self.mean  # Denormalise\n",
    "            predicted_trajectory[t] = x_val_out\n",
    "\n",
    "        self._plot_trajectory(predicted_trajectory,\n",
    "                              title=f'{self.model_type.capitalize()} model predicted', vmin=-10, vmax=15)\n",
    "        # plot validation trajectory\n",
    "        val_trajectory = np.zeros((steps, Nx))\n",
    "        for t in range(steps):\n",
    "            x_val = data_set[t+1][0]\n",
    "            val_trajectory[t] = x_val.numpy() * self.std + self.mean\n",
    "        self._plot_trajectory(val_trajectory, title='True', vmin=-10, vmax=15)\n",
    "        # plot the error\n",
    "        error = predicted_trajectory - val_trajectory\n",
    "        self._plot_trajectory(error, title=f'{self.model_type.capitalize()} model error',\n",
    "                              vmin=-15, vmax=15)\n",
    "\n",
    "    def _plot_trajectory(self, trajectory, title='Predicted', vmin=None, vmax=None):\n",
    "        if vmin is not None and vmin == -vmax:\n",
    "            cmap = cmocean.cm.balance\n",
    "        else:\n",
    "            cmap = cmocean.cm.curl\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(trajectory.T, aspect='auto', cmap=cmap,\n",
    "                   origin='lower', interpolation='spline36', vmin=vmin, vmax=vmax)\n",
    "        cbar_label = 'Error value' if 'Error' in title else 'State value'\n",
    "        plt.colorbar(label=cbar_label)\n",
    "        plt.xlabel('Time step')\n",
    "        plt.ylabel('Lorenz96 variables')\n",
    "        plt.title(f'{title} Lorenz-96 trajectory')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'{PATH}/{title.replace(\" \", \"_\").lower()}_traj.png', dpi=300)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff06b18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Nt_train = 10000\n",
    "\n",
    "# Use double precision, simple precision could also be used\n",
    "torch.set_default_dtype(torch.float64)\n",
    "true_model = Lorenz96(Nx=40, dt=0.01, F=8.0, integrator='rk4')\n",
    "xt = true_model.generate_dataset(\n",
    "    Nt_train=Nt_train, Nt_spinup=1000, seed=42, Nt_shift=10)\n",
    "# change xt to double precision\n",
    "xt = xt.astype(np.float64)\n",
    "\n",
    "# Plot heatmap of trajectory\n",
    "plot_lorenz96_trajectory(xt, Nt=50, mode='heatmap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904db4f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set, val_set, mean, std = preprocess_dataset(xt)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46db51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_type=\"naive\"\n",
    "# Initialize model\n",
    "model = NaiveNetwork(Nx=true_model.Nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d9737",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# Train the model\n",
    "trainer = Trainer(model, train_loader, val_loader, mean, std,\n",
    "                    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                    model_type=model_type)\n",
    "trainer.train(epochs=epochs, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b658e6e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Nt = 25\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(\n",
    "    f'{PATH}/stored_{model_type}_best_network.pth', weights_only=True))\n",
    "\n",
    "# Predictions\n",
    "inference = Inference(model, mean, std, model_type=model_type,\n",
    "                        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "inference.predict_trajectory(val_set, steps=Nt, Nx=true_model.Nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563795bf",
   "metadata": {},
   "source": [
    "### 2. Convolutional neural network (CNN)\n",
    "A convolutional neural network that takes the state $x_t$ as input and outputs the state $x_{t+1}$ at the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffffa60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self, Nx, num_filters=64, kernel_size=5):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "        self.Nx = Nx\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=num_filters,\n",
    "                               kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=num_filters, out_channels=1,\n",
    "                               kernel_size=kernel_size, padding=kernel_size//2)\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add channel dimension and apply convolutions\n",
    "        x = x.unsqueeze(1)  # (B, 1, Nx) -- Add channel dimension\n",
    "        x = self.relu(self.conv1(x))  # Apply Conv1\n",
    "        x = self.conv4(x)  # Apply Conv4 to reduce to 1 channel\n",
    "        return x.squeeze(1)  # Remove channel dimension and return (B, Nx)\n",
    "\n",
    "    def predict(self, x, steps=1):\n",
    "        \"\"\"\n",
    "        Predict the next state using the model for a given number of steps.\n",
    "        \"\"\"\n",
    "        for _ in range(steps):\n",
    "            x = self.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a874a28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_type = 'conv'\n",
    "model = ConvolutionalNetwork(\n",
    "    Nx=true_model.Nx, num_filters=64, kernel_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377b4e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# Train the model\n",
    "trainer = Trainer(model, train_loader, val_loader, mean, std,\n",
    "                    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                    model_type=model_type)\n",
    "trainer.train(epochs=epochs, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f0b75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Nt = 25\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(\n",
    "    f'{PATH}/stored_{model_type}_best_network.pth', weights_only=True))\n",
    "\n",
    "# Predictions\n",
    "inference = Inference(model, mean, std, model_type=model_type,\n",
    "                        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "inference.predict_trajectory(val_set, steps=Nt, Nx=true_model.Nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647368ca",
   "metadata": {},
   "source": [
    "### 3. Hybrid model\n",
    "A hybrid model that combines: a CNN-based architecture for computing the tendency $\\frac{dx}{dt}$, an explicit integration scheme (Euler, RK2, RK4), and periodic padding to enforce spatial boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550c604",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class HybridNetwork(nn.Module):\n",
    "    def __init__(self, Nx, num_filters=6, kernel_size=5, dt=0.01, integrator='euler'):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.Nx = Nx\n",
    "        self.dt = dt\n",
    "        self.border = kernel_size // 2\n",
    "        self.integrator = integrator\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=1, out_channels=num_filters, kernel_size=kernel_size)\n",
    "        self.conv2 = nn.Conv1d(in_channels=num_filters * 2,\n",
    "                               out_channels=1, kernel_size=1)\n",
    "\n",
    "    def pad(self, x):\n",
    "        # Periodic padding\n",
    "        left = x[..., -self.border:]\n",
    "        right = x[..., :self.border]\n",
    "        return torch.cat([left, x, right], dim=-1)\n",
    "\n",
    "    def tendency(self, x):\n",
    "        x = x.unsqueeze(1)  # (B, 1, Nx)\n",
    "        x_pad = self.pad(x)  # Periodic padding\n",
    "\n",
    "        x1 = self.conv1(x_pad)  # (B, F, Nx)\n",
    "        x2 = x1 ** 2            # Quadratic nonlinearity\n",
    "\n",
    "        x_cat = torch.cat([x1, x2], dim=1)  # (B, 2F, Nx)\n",
    "        out = self.conv2(x_cat)             # (B, 1, Nx)\n",
    "\n",
    "        return out.squeeze(1)               # (B, Nx)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.integrator == 'euler':\n",
    "            return self.euler_step(x)\n",
    "        elif self.integrator == 'rk2':\n",
    "            return self.rk2_step(x)\n",
    "        elif self.integrator == 'rk4':\n",
    "            return self.rk4_step(x)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid integrator. Use 'euler', 'rk2', or 'rk4'.\")\n",
    "\n",
    "    def euler_step(self, x):\n",
    "        \"\"\"\n",
    "        Euler integration step.\n",
    "        \"\"\"\n",
    "        dx = self.tendency(x)\n",
    "        return x + self.dt * dx\n",
    "\n",
    "    def rk2_step(self, x):\n",
    "        \"\"\"\n",
    "        Runge-Kutta 2nd order integration\n",
    "        \"\"\"\n",
    "        k1 = self.tendency(x)\n",
    "        k2 = self.tendency(x + self.dt * k1)\n",
    "        dx = (k1 + k2) / 2\n",
    "        return x + self.dt * dx\n",
    "\n",
    "    def rk4_step(self, x):\n",
    "        \"\"\"\n",
    "        Runge-Kutta 4th order integration\n",
    "        \"\"\"\n",
    "        k1 = self.tendency(x)\n",
    "        k2 = self.tendency(x + 0.5 * self.dt * k1)\n",
    "        k3 = self.tendency(x + 0.5 * self.dt * k2)\n",
    "        k4 = self.tendency(x + self.dt * k3)\n",
    "        dx = (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
    "        return x + self.dt * dx\n",
    "\n",
    "    def predict(self, x, steps=1):\n",
    "        \"\"\"\n",
    "        Predict the next state using the model for a given number of steps.\n",
    "        \"\"\"\n",
    "        for _ in range(steps):\n",
    "            x = self.forward(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f3e49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_type=\"hybrid\"\n",
    "# hybrid network\n",
    "# Use the same parameters as the true model\n",
    "# Nx = true_model.Nx, dt = true_model.dt, integrator = true_model.integrator\n",
    "model = HybridNetwork(Nx=true_model.Nx, num_filters=6,\n",
    "                        kernel_size=5, dt=true_model.dt, integrator='rk4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f75e3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# Train the model\n",
    "trainer = Trainer(model, train_loader, val_loader, mean, std,\n",
    "                    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                    model_type=model_type)\n",
    "trainer.train(epochs=epochs, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda9d73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Nt = 25\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(\n",
    "    f'{PATH}/stored_{model_type}_best_network.pth', weights_only=True))\n",
    "\n",
    "# Predictions\n",
    "inference = Inference(model, mean, std, model_type=model_type,\n",
    "                        device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "inference.predict_trajectory(val_set, steps=Nt, Nx=true_model.Nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5cc78",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this practical session, we explored several neural network architectures for modelling the dynamics of chaotic systems. \n",
    "The key takeaway is that incorporating domain knowledge—such as the structure of the underlying physical equations or the use of numerical integration schemes—can significantly enhance the performance and robustness of learned surrogate models. \n",
    "\n",
    "These type of approaches are particularly relevant in the context of data assimilation, where surrogate models that respect physical laws are essential for reliable forecasting. This line of research is actively being pursued in operational weather and climate modelling, and it is expected to play an increasingly important role in the future of Earth system prediction."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
